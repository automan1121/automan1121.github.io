<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>零碎知识点</title>
      <link href="/2019/03/27/%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2019/03/27/%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="零碎知识点"><a href="#零碎知识点" class="headerlink" title="零碎知识点"></a><font color="#2674BA">零碎知识点</font></h1><h3 id="Q1-数据归一化、标准化"><a href="#Q1-数据归一化、标准化" class="headerlink" title="Q1:数据归一化、标准化  "></a><font color="#F77A0B">Q1:数据归一化、标准化  </font></h3><table><thead><tr><th style="text-align:center"></th><th style="text-align:left">归一化</th><th style="text-align:left">标准化</th></tr></thead><tbody><tr><td style="text-align:center">特点</td><td style="text-align:left">数据缩放到0-1区间<br>不同维度的特征对目标函数的影响权重一致                       <br>由最大最小值决定<br>改变了原数据分布(梯度下降等高线由椭圆变成圆)</td><td style="text-align:left">消除量纲<br>不同维度的特征具有可比性 <br>由数据的整体分布决定<br>不改变原数据分布</td></tr><tr><td style="text-align:center">常用方法</td><td style="text-align:left">$$ x^* = \frac{x-min}{max-min} $$</td><td style="text-align:left"><p align="left">    $$ x^* = \frac{x-\bar x}{\sigma} $$  </p></td></tr><tr><td style="text-align:center">使用场景</td><td style="text-align:left">输出结果范围有要求<br>数据较稳定，不存在极端的最大最小值</td><td style="text-align:left">数据存在异常值和较多噪音</td></tr></tbody></table><p>哪些模型需要归一化、哪些不需要？</p><ul><li>使用梯度下降优化的模型最好归一化，归一化后损失函数的等高线接近圆形，收敛速度加快。</li><li>树型模型不需要归一化，分割点的选取与特征的绝对值大小无关</li></ul><h3 id="Q2-正则化"><a href="#Q2-正则化" class="headerlink" title="Q2:正则化  "></a><font color="#F77A0B">Q2:正则化  </font></h3><p>什么叫正则化？常见的正则化有哪些？</p><ul><li><p>为了防止过拟合，在损失函数的基础上增加一个<font color="#F77A0B"><strong>参数的惩罚项</strong></font>（正则），使训练误差最小化时，模型的复杂度尽可能低，保证模型的泛化能力。</p></li><li><p>常见的有L0、L1、L2。L0、L1实现<font color="#F77A0B"><strong>稀疏</strong></font>（稀疏可特征选择、提高可解释性），L2实现<font color="#F77A0B"><strong>平滑</strong></font>（权值衰减，防止过拟合）。</p><ul><li>L0：向量中非0的个数，最小化L0即希望参数矩阵w中大部分元素都为0。</li><li>L1：向量中的各元素绝对值之和$||w||_1$，最小化L1即参数矩阵w中大部分元素都为0（$||w||_1$在0不可导，参数以固定速率下降到0），L1为L0的近似解。</li><li>L2：向量中的各元素平方之和$||w||_2$，最小化L2即参数矩阵w中大部分元素都接近0（$||w||_1$在0可导，参数约接近0下降速率越慢，越平滑）。</li></ul></li></ul><p>正则化为什么能增加模型的泛化能力，防止过拟合？</p><ul><li><p>什么叫过拟合？造成过拟合的原因？</p><ul><li><p>过拟合：模型在训练数据表现好但在验证数据表现差的现象。</p></li><li><p>原因：1.训练数据与验证数据分布差异大。（训练数据噪声大、训练样本小等）<br>           2.模型复杂度过高。（参数过多、参数值过大等）</p></li><li><p>举例：1.模型学习到的是噪声数据（知识）或者小样本知识，但是这些代表不了实际场景知识。<br></p><p>​           2.参数过多（极端情况下，无穷个参数一定能拟合任何曲线）、参数值过大（需要拟合所有的样本点，拟合曲线的波动大，当x小而需要y大时则w大）。</p></li></ul></li><li><p>正则化通过约束参数的数目与大小，来解决由参数引起的过拟合。</p></li><li>“欧姆剃刀”：训练误差最小的同时模型的复杂度越低，模型的泛化能力越强。</li></ul><p>L1与L2差异？</p><ul><li></li><li></li></ul><p>L1、L2的使用场景？什么时候L1优于L2？什么时候使用L1+L2?</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归</title>
      <link href="/2019/03/27/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
      <url>/2019/03/27/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>逻辑回归</title>
      <link href="/2019/03/27/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
      <url>/2019/03/27/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2019年计划</title>
      <link href="/2019/01/20/2019%E5%B9%B4%E8%AE%A1%E5%88%92/"/>
      <url>/2019/01/20/2019%E5%B9%B4%E8%AE%A1%E5%88%92/</url>
      
        <content type="html"><![CDATA[<ul><li>1.</li><li>2.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计划 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 2019 </tag>
            
            <tag> 计划 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于本站</title>
      <link href="/2019/01/20/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99/"/>
      <url>/2019/01/20/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>本站域名 <a href="http://babylls.com" target="_blank" rel="noopener">http://babylls.com</a> 站内分享一些机器学习、深度学习、数据挖掘、编程语言相关的文章。学识尚浅，文中难免会有错误，如您发现，请邮件(<a href="mailto:babylls@163.com" target="_blank" rel="noopener">babylls@163.com</a>)告知，同时也欢迎与我交流。</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
